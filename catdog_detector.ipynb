{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92mQ2gMlYoZl"
   },
   "source": [
    "# Transfer learning / fine-tuning\n",
    "\n",
    "Original script: https://colab.research.google.com/github/kylemath/ml4a-guides/blob/master/notebooks/transfer-learning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3p-OjhDPYoZm"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "#if using Theano with GPU\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.utils import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8OGRcLNwYoZu",
    "outputId": "0045ec77-f6a6-4bd7-9ff4-48a7dd559d3b"
   },
   "outputs": [],
   "source": [
    "root = 'PetImages'\n",
    "exclude = []\n",
    "train_split, val_split = 0.7, 0.15\n",
    "\n",
    "categories = [x[0] for x in os.walk(root) if x[0]][1:]\n",
    "categories = [c for c in categories if c not in [os.path.join(root, e) for e in exclude]]\n",
    "\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2ERhVlFYoZy"
   },
   "source": [
    "This function is useful for pre-processing the data into an image and input vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A1T1Joq7YoZz"
   },
   "outputs": [],
   "source": [
    "# helper function to load image and return it and input vector\n",
    "def get_image(path):\n",
    "    img = load_img(path, target_size=(224, 224))\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return img, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUwQ60GGYoZ3"
   },
   "source": [
    "Load all the images from root folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "5nAUr-ooYoZ4",
    "outputId": "387a70f0-caae-4f6a-8936-a1e6779f475b"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for c, category in enumerate(categories):\n",
    "    images = [os.path.join(dp, f) for dp, dn, filenames \n",
    "              in os.walk(category) for f in filenames \n",
    "              if os.path.splitext(f)[1].lower() in ['.jpg','.png','.jpeg']]\n",
    "    for img_path in images:\n",
    "        try:   \n",
    "            img, x = get_image(img_path)\n",
    "            data.append({'x':np.array(x[0]), 'y':c})\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# count the number of classes\n",
    "num_classes = len(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55Rw-ptVYoZ7"
   },
   "source": [
    "Randomize the data order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5vGeJK55YoZ8"
   },
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OwHqS_NgYoZ_"
   },
   "source": [
    "create training / validation / test split (70%, 15%, 15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PT9Cuq2rYoaB"
   },
   "outputs": [],
   "source": [
    "idx_val = int(train_split * len(data))\n",
    "idx_test = int((train_split + val_split) * len(data))\n",
    "train = data[:idx_val]\n",
    "val = data[idx_val:idx_test]\n",
    "test = data[idx_test:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsOVhpqcYoaF"
   },
   "source": [
    "Separate data for labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "vQOGN9kOYoaH",
    "outputId": "b992f7bd-aca6-4d4d-e79d-9efaeeb7d2be"
   },
   "outputs": [],
   "source": [
    "x_train, y_train = np.array([t[\"x\"] for t in train]), [t[\"y\"] for t in train]\n",
    "x_val, y_val = np.array([t[\"x\"] for t in val]), [t[\"y\"] for t in val]\n",
    "x_test, y_test = np.array([t[\"x\"] for t in test]), [t[\"y\"] for t in test]\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vc6W07QVYoaM"
   },
   "source": [
    "Pre-process the data as before by making sure it's float32 and normalized between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "qnXaiAgJYoaQ",
    "outputId": "4f20cdc6-c6a4-4f88-e45f-e7fbedfcdc55"
   },
   "outputs": [],
   "source": [
    "# normalize data\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_val = x_val.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "# convert labels to one-hot vectors\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ordUucUKYoaS"
   },
   "source": [
    "Let's get a summary of what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "AcKjxgtyYoaT",
    "outputId": "7b8456a1-472b-45ce-818f-3b0f670aac94"
   },
   "outputs": [],
   "source": [
    "# summary\n",
    "print(\"finished loading %d images from %d categories\"%(len(data), num_classes))\n",
    "print(\"train / validation / test split: %d, %d, %d\"%(len(x_train), len(x_val), len(x_test)))\n",
    "print(\"training data shape: \", x_train.shape)\n",
    "print(\"training labels shape: \", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-P9MNPcYoaY"
   },
   "source": [
    "If everything worked properly, you should have loaded a bunch of images, and split them into three sets: `train`, `val`, and `test`. The shape of the training data should be (`n`, 224, 224, 3) where `n` is the size of your training set, and the labels should be (`n`, `c`) where `c` is the number of classes. \n",
    "\n",
    "Notice that we divided all the data into three subsets -- a training set `train`, a validation set `val`, and a test set `test`. The reason for this is to properly evaluate the accuracy of our classifier. During training, the optimizer uses the validation set to evaluate its internal performance, in order to determine the gradient without overfitting to the training set. The `test` set is always held out from the training algorithm, and is only used at the end to evaluate the final accuracy of our model.\n",
    "\n",
    "Let's quickly look at a few sample images from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "id": "y84SmM2CYoaZ",
    "outputId": "37c0137b-d993-4b2d-fa4b-51fe368e8fa1"
   },
   "outputs": [],
   "source": [
    "images = [os.path.join(dp, f) for dp, dn, filenames in os.walk(root) for f in filenames if os.path.splitext(f)[1].lower() in ['.jpg','.png','.jpeg']]\n",
    "idx = [int(len(images) * random.random()) for i in range(8)]\n",
    "imgs = [load_img(images[i], target_size=(224, 224)) for i in idx]\n",
    "concat_image = np.concatenate([np.asarray(img) for img in imgs], axis=1)\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.imshow(concat_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIwMY_ZXYoax"
   },
   "source": [
    "## Transfer learning by starting with existing network\n",
    "\n",
    "Now we can move on to the main strategy for training an image classifier on our small dataset: by starting with a larger and already trained network.\n",
    "\n",
    "To start, we will load the VGG16 from keras, which was trained on ImageNet and the weights saved online. If this is your first time loading VGG16, you'll need to wait a bit for the weights to download from the web. Once the network is loaded, we can again inspect the layers with the `summary()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 952
    },
    "id": "KpUDAbxiYoay",
    "outputId": "ed9ec74b-6697-438b-8e82-61df8c9da39f"
   },
   "outputs": [],
   "source": [
    "vgg = keras.applications.VGG16(weights='imagenet', include_top=True)\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLXTofcNYoa2"
   },
   "source": [
    "Notice that VGG16 contains 13 convolutional layers and two fully connected layers at the end, and has over 138 million parameters, around 100 times as many parameters than the network we made above. The majority of the parameters are stored in the connections leading into the first fully-connected layer.\n",
    "\n",
    "VGG16 was made to solve ImageNet, and achieves a [8.8% top-5 error rate](https://github.com/jcjohnson/cnn-benchmarks), which means that 91.2% of test samples were classified correctly within the top 5 predictions for each image. It's top-1 accuracy is 73%.\n",
    "\n",
    "In order to use this network for our task, we \"remove\" the final classification layer, the 1000-neuron softmax layer at the end, which corresponds to ImageNet, and instead replace it with a new softmax layer for our dataset.\n",
    "\n",
    "In terms of implementation, it's easier to simply create a copy of VGG from its input layer until the second to last layer, and then work with that, rather than modifying the VGG object directly. So technically we never \"remove\" anything, we just circumvent/ignore it. This can be done in the following way, by using the keras `Model` class to initialize a new model whose input layer is the same as VGG but whose output layer is our new softmax layer, called `new_classification_layer`. Note: although it appears we are duplicating this large network, internally Keras is actually just copying all the layers by reference, and thus we don't need to worry about overloading the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rFL-fLitYoa3"
   },
   "outputs": [],
   "source": [
    "# make a reference to VGG's input layer\n",
    "inp = vgg.input\n",
    "\n",
    "# make a new softmax layer with num_classes neurons\n",
    "new_classification_layer = Dense(num_classes, activation='softmax')\n",
    "\n",
    "# connect our new layer to the second to last layer in VGG, and make a reference to it\n",
    "out = new_classification_layer(vgg.layers[-2].output)\n",
    "\n",
    "# create a new network between inp and out\n",
    "model_new = Model(inp, out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBIp3fbQYoa9"
   },
   "source": [
    "We are going to retrain this network, `model_new` on the new dataset and labels. But first, we need to freeze the weights and biases in all the layers in the network, except our new one at the end, with the expectation that the features that were learned in VGG should still be fairly relevant to the new image classification task. Not optimal, but most likely better than what we can train to in our limited dataset. \n",
    "\n",
    "By setting the `trainable` flag in each layer false (except our new classification layer), we ensure all the weights and biases in those layers remain fixed, and we simply train the weights in the one layer at the end. In some cases, it is desirable to *not* freeze all the pre-classification layers. If your dataset has enough samples, and doesn't resemble ImageNet very much, it might be advantageous to fine-tune some of the VGG layers along with the new classifier, or possibly even all of them. To do this, you can change the below code to make more of the layers trainable.\n",
    "\n",
    "In this case, we will just do feature extraction, fearing that fine-tuning too much with this dataset may overfit. But maybe we are wrong? A good exercise would be to try out both, and compare the results.\n",
    "\n",
    "So we go ahead and freeze the layers, and compile the new model with exactly the same optimizer and loss function as in our first network, for the sake of a fair comparison. We then run `summary` again to look at the network's architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918
    },
    "id": "e_n5A8oGYoa9",
    "outputId": "ebe81af3-f953-4351-ef10-5b63f3d19d75"
   },
   "outputs": [],
   "source": [
    "# make all layers untrainable by freezing weights (except for last layer)\n",
    "for l, layer in enumerate(model_new.layers[:-1]):\n",
    "    layer.trainable = False\n",
    "\n",
    "# ensure the last layer is trainable/not frozen\n",
    "for l, layer in enumerate(model_new.layers[-1:]):\n",
    "    layer.trainable = True\n",
    "\n",
    "model_new.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "aDdq71XNYobD",
    "outputId": "907479a2-3a12-44b7-b706-3f86e3a4ea26"
   },
   "outputs": [],
   "source": [
    "history = model_new.fit(x_train, y_train, \n",
    "                         batch_size=128, \n",
    "                         epochs=10, \n",
    "                         validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "id": "SHLdHnuuYobJ",
    "outputId": "bd5a066f-c94c-4ac4-adc5-3154e6143a29"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,4))\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(history.history[\"val_loss\"])\n",
    "ax.set_title(\"validation loss\")\n",
    "ax.set_xlabel(\"epochs\")\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.plot(history.history[\"val_accuracy\"])\n",
    "ax2.set_title(\"validation accuracy\")\n",
    "ax2.set_xlabel(\"epochs\")\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "zMxC6Pd1YobN",
    "outputId": "944eede7-79a7-42b3-ba26-bd883c2e7b46"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model_new.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4iUykardYobR"
   },
   "source": [
    "To predict a new image, simply run the following code to get the probabilities for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "YpRcsywEYobT",
    "outputId": "858eb7b8-f403-451c-83b9-7eda70671cfc"
   },
   "outputs": [],
   "source": [
    "img, x = get_image('testImages/cat.jfif')\n",
    "probabilities = model_new.predict([x])\n",
    "\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(categories[0],\": \", \"{:.2f}%\".format(probabilities[0][0]*100))\n",
    "print(categories[1],\": \", \"{:.2f}%\".format(probabilities[0][1]*100))\n",
    "print(categories[2],\": \", \"{:.2f}%\".format(probabilities[0][2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new.save('catdog_detector_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new.save('./catdog_detector_v1_h5/catdog_detector_v1.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CÃ³pia de transfer-learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
